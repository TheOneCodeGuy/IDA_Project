{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib nbagg\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Initial Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Data/TrainingData.csv', index_col=0)\n",
    "\n",
    "data.replace('missing', np.nan, inplace=True)\n",
    "data.replace('na', np.nan, inplace=True)\n",
    "int_cols = list(set(data.columns) - {'mvar47'})\n",
    "data[int_cols] = data[int_cols].astype(float)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['default_ind']\n",
    "\n",
    "X_cols = list(data.columns)\n",
    "X_cols.remove('default_ind')\n",
    "\n",
    "X = data[X_cols]\n",
    "\n",
    "X.loc[X['mvar47'] == 'L', 'mvar47'] = 1\n",
    "X.loc[X['mvar47'] == 'C', 'mvar47'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['mvar47', 'mvar48']\n",
    "numeric = list(X.columns)\n",
    "\n",
    "for var in categorical:\n",
    "    numeric.remove(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(X_Scaler.fit_transform(X[numeric]), columns=X[numeric].columns, index=X.index)\n",
    "X_scaled[categorical] = X[categorical]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_impute(data, cols, type_='mean'):\n",
    "    \n",
    "    if type_ == 'mean':\n",
    "        return data.fillna(data[cols].mean()) \n",
    "    \n",
    "    if type_ == 'median':\n",
    "        return data.fillna(data[cols].median())\n",
    "    \n",
    "    if type_ =='mode':\n",
    "        md = data[cols].mode()\n",
    "        return data.fillna(md.iloc[0]) \n",
    "    \n",
    "    if type_ == 'CF': #CF - Customer friendly\n",
    "        imp_vals = data.mean()\n",
    "        v = [40,31,41,45,35,46,24,16,17,18,12,9,39,2,42,43]\n",
    "        for i in v:\n",
    "            imp_vals['mvar'+str(i)] = 0\n",
    "        med = data.median()\n",
    "        imp_vals['mvar11'] = med['mvar11']\n",
    "        \n",
    "        return data.fillna(imp_vals[cols])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_impute(cols_to_impute, X, numeric, train_na_method='mean'):\n",
    "    \n",
    "    for col in cols_to_impute:\n",
    "        \n",
    "        other_cols = [c for c in numeric if (c != col)]\n",
    "\n",
    "        X_train = X.loc[~X[col].isna(), other_cols]\n",
    "        y_train = X.loc[~X[col].isna(), col]\n",
    "\n",
    "        X_test = X.loc[X[col].isna(), other_cols]\n",
    "        \n",
    "        # Impute KNN training data with basci impute\n",
    "        X_train = basic_impute(X_train, other_cols, type_=train_na_method)\n",
    "        X_test = basic_impute(X_test, other_cols, type_=train_na_method)\n",
    "    \n",
    "        # 0.1 % of the data as neighbours\n",
    "        model = KNeighborsRegressor(int(0.001*len(X_train)))\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        X.loc[X_test.index, col] = model.predict(X_test)\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_impute = ['mvar9'] # Choose columns you want to impute using the KNN method\n",
    "\n",
    "X_scaled_imputed = KNN_impute(cols_to_impute, X_scaled, numeric, train_na_method='CF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance Inflation Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIFs = {}\n",
    "\n",
    "for var in data.columns:\n",
    "\n",
    "    ### Remove this after encoding is done\n",
    "    \n",
    "    if var in ['mvar48']:\n",
    "        continue\n",
    "    \n",
    "    #######################################\n",
    "    \n",
    "    var_y = data[var]\n",
    "    var_X = data.drop(var, axis=1)\n",
    "    \n",
    "    linmod = LinearRegression()\n",
    "    linmod.fit(var_X, var_y)\n",
    "    R2 = linmod.score(var_X, var_y)\n",
    "    VIF[var] = 1 / (1 - R2)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(range(len(VIFs)), VIFs.values(), width=0.7)\n",
    "plt.ylabel('VIF')\n",
    "plt.xlabel('Variable')\n",
    "plt.title('VIF of Variables')\n",
    "plt.xticks(range(len(VIFs)), VIFs.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat = np.round(np.cov(np.array(X_final[numeric]).T), 3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(40, 40))\n",
    "img = ax.matshow(cov_mat, cmap='Reds')\n",
    "fig.colorbar(img, aspect=50)\n",
    "ax.set_title('Covariance')\n",
    "ax.set_xticks(ticks=range(len(numeric)))\n",
    "ax.set_yticks(ticks=range(len(numeric)))\n",
    "\n",
    "for (i, j), z in np.ndenumerate(cov_mat):\n",
    "    ax.text(j, i, '{:0.3f}'.format(z), ha='center', va='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
