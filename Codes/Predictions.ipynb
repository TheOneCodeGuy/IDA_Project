{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as gbm\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "%matplotlib nbagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\vasistha singhal\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3057: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('testX.csv', index_col=0)\n",
    "X_train = pd.read_csv('TrainingData.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('TrainingData.csv', index_col=0)\n",
    "# X_data = data.drop('default_ind', axis=1)  \n",
    "# y_data = data['default_ind']\n",
    "# X_train_data, X_test_data, y_train_data, y_test_data = train_test_split(X_data, y_data, test_size=0.125)\n",
    "\n",
    "# X_train = pd.DataFrame.copy(X_train_data)\n",
    "# X_train['default_ind']  = y_train_data\n",
    "\n",
    "# X = X_test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding(train_data,test_data=None):\n",
    "    \n",
    "    counts = train_data.groupby('mvar48')['default_ind'].count()\n",
    "    means = train_data.groupby('mvar48')['default_ind'].mean()\n",
    "    m = 0\n",
    "    smooth_mean = (counts * means + m * train_data['mvar48'].mean()) / (counts + m)\n",
    "    enc_48 = dict(smooth_mean)\n",
    "    train_data['mvar48'] = train_data['mvar48'].map(enc_48)\n",
    "    train_data = train_data.replace({'C':0,'L':1})\n",
    "   \n",
    "    test_data = test_data.replace({'C':0,'L':1})\n",
    "    test_data['mvar48'] = test_data['mvar48'].map(enc_48)\n",
    "    return train_data, test_data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.replace('missing', np.nan, inplace=True)\n",
    "X.replace('na', np.nan, inplace=True)\n",
    "int_cols = list(set(X.columns) - {'mvar47'})\n",
    "X[int_cols] = X[int_cols].astype(float)\n",
    "\n",
    "X_train.replace('missing', np.nan, inplace=True)\n",
    "X_train.replace('na', np.nan, inplace=True)\n",
    "int_cols = list(set(X_train.columns) - {'mvar47'})\n",
    "X_train[int_cols] = X_train[int_cols].astype(float)\n",
    "\n",
    "X_train_enc, X_enc = encoding(X_train,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = list(X_enc.columns)\n",
    "nan_per = X_enc.isna().sum(axis=0)/X_enc.shape[0]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(cols,nan_per)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title('Fraction of missing values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_scaler = pickle.load(open('pre_KNN_scaler.sav', 'rb'))\n",
    "X_scaled = pd.DataFrame(initial_scaler.transform(X_enc), columns = X_enc.columns, index=X_enc.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_impute(data, cols, type_='mean'):\n",
    "    \n",
    "    if type_ == 'mean':\n",
    "        return data.fillna(data[cols].mean()) \n",
    "    \n",
    "    if type_ == 'median':\n",
    "        return data.fillna(data[cols].median())\n",
    "    \n",
    "    if type_ =='mode':\n",
    "        md = data[cols].mode()\n",
    "        return data.fillna(md.iloc[0]) \n",
    "    \n",
    "    if type_ == 'CF': #CF - Customer friendly\n",
    "        imp_vals = data.mean()\n",
    "        v = [40,31,41,45,35,46,24,16,17,18,12,9,39,2,42,43]\n",
    "        for i in v:\n",
    "            imp_vals['mvar'+str(i)] = 0\n",
    "        med = data.median()\n",
    "        imp_vals['mvar11'] = med['mvar11']\n",
    "        \n",
    "        return data.fillna(imp_vals[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_impute(cols_to_impute, X, train_na_method='median'):\n",
    "    \n",
    "    result = X.copy()\n",
    "\n",
    "    X_nonan = basic_impute(X, X.columns, type_=train_na_method)\n",
    "\n",
    "    for col in cols_to_impute:\n",
    "\n",
    "        X_train = X_nonan.loc[~X[col].isna()].drop(col, axis=1)\n",
    "        y_train = X_nonan.loc[~X[col].isna(), col]\n",
    "\n",
    "        X_test = X_nonan.loc[X[col].isna()].drop(col, axis=1)\n",
    "        \n",
    "        if len(X_test) == 0:\n",
    "            print('No need to impute', col)\n",
    "            continue\n",
    "        \n",
    "        print(col, ': Number of NaNs -', len(X_test))\n",
    "        \n",
    "        # 0.1 % of the data as neighbours\n",
    "        model = KNeighborsRegressor(int(0.001*len(X_train)))\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        result.loc[X_test.index, col] = model.predict(X_test)\n",
    "        \n",
    "        print('Imputed for', col)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mvar1 : Number of NaNs - 2228\n",
      "Imputed for mvar1\n",
      "mvar2 : Number of NaNs - 3327\n",
      "Imputed for mvar2\n",
      "mvar3 : Number of NaNs - 294\n",
      "Imputed for mvar3\n",
      "mvar4 : Number of NaNs - 294\n",
      "Imputed for mvar4\n",
      "mvar5 : Number of NaNs - 294\n",
      "Imputed for mvar5\n",
      "mvar6 : Number of NaNs - 11297\n",
      "Imputed for mvar6\n",
      "mvar7 : Number of NaNs - 4479\n",
      "Imputed for mvar7\n",
      "mvar8 : Number of NaNs - 11302\n",
      "Imputed for mvar8\n",
      "mvar9 : Number of NaNs - 6812\n",
      "Imputed for mvar9\n",
      "mvar10 : Number of NaNs - 295\n",
      "Imputed for mvar10\n",
      "mvar11 : Number of NaNs - 26518\n",
      "Imputed for mvar11\n",
      "mvar12 : Number of NaNs - 8397\n",
      "Imputed for mvar12\n",
      "mvar13 : Number of NaNs - 5807\n",
      "Imputed for mvar13\n",
      "No need to impute mvar14\n",
      "mvar15 : Number of NaNs - 18836\n",
      "Imputed for mvar15\n",
      "mvar16 : Number of NaNs - 11033\n",
      "Imputed for mvar16\n",
      "mvar17 : Number of NaNs - 9432\n",
      "Imputed for mvar17\n",
      "mvar18 : Number of NaNs - 8785\n",
      "Imputed for mvar18\n",
      "mvar19 : Number of NaNs - 7\n",
      "Imputed for mvar19\n",
      "mvar20 : Number of NaNs - 295\n",
      "Imputed for mvar20\n",
      "mvar21 : Number of NaNs - 13380\n",
      "Imputed for mvar21\n",
      "mvar22 : Number of NaNs - 17368\n",
      "Imputed for mvar22\n",
      "mvar23 : Number of NaNs - 23977\n",
      "Imputed for mvar23\n",
      "mvar24 : Number of NaNs - 11266\n",
      "Imputed for mvar24\n",
      "mvar25 : Number of NaNs - 4598\n",
      "Imputed for mvar25\n",
      "mvar26 : Number of NaNs - 6435\n",
      "Imputed for mvar26\n",
      "mvar27 : Number of NaNs - 7951\n",
      "Imputed for mvar27\n",
      "mvar28 : Number of NaNs - 295\n",
      "Imputed for mvar28\n",
      "mvar29 : Number of NaNs - 295\n",
      "Imputed for mvar29\n",
      "mvar30 : Number of NaNs - 21475\n",
      "Imputed for mvar30\n",
      "mvar31 : Number of NaNs - 33143\n",
      "Imputed for mvar31\n",
      "mvar32 : Number of NaNs - 4598\n",
      "Imputed for mvar32\n",
      "mvar33 : Number of NaNs - 1037\n",
      "Imputed for mvar33\n",
      "mvar34 : Number of NaNs - 295\n",
      "Imputed for mvar34\n",
      "mvar35 : Number of NaNs - 19765\n",
      "Imputed for mvar35\n",
      "mvar36 : Number of NaNs - 1730\n",
      "Imputed for mvar36\n",
      "mvar37 : Number of NaNs - 4598\n",
      "Imputed for mvar37\n",
      "mvar38 : Number of NaNs - 295\n",
      "Imputed for mvar38\n",
      "mvar39 : Number of NaNs - 3628\n",
      "Imputed for mvar39\n",
      "mvar40 : Number of NaNs - 36901\n",
      "Imputed for mvar40\n",
      "mvar41 : Number of NaNs - 32258\n",
      "Imputed for mvar41\n",
      "mvar42 : Number of NaNs - 1167\n",
      "Imputed for mvar42\n",
      "mvar43 : Number of NaNs - 494\n",
      "Imputed for mvar43\n",
      "mvar44 : Number of NaNs - 4683\n",
      "Imputed for mvar44\n",
      "mvar45 : Number of NaNs - 26034\n",
      "Imputed for mvar45\n",
      "mvar46 : Number of NaNs - 13567\n",
      "Imputed for mvar46\n",
      "No need to impute mvar47\n",
      "mvar48 : Number of NaNs - 8\n",
      "Imputed for mvar48\n"
     ]
    }
   ],
   "source": [
    "X_scaled_imputed = KNN_impute(X_scaled.columns, X_scaled, train_na_method='median')\n",
    "X_rescaled = pd.DataFrame(initial_scaler.inverse_transform(X_scaled_imputed), columns=X_scaled_imputed.columns, index=X_scaled_imputed.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_creator(cols_list, X):\n",
    "    y = X.copy()\n",
    "    columns = X.columns\n",
    "    for i in range(len(columns)):\n",
    "        f1 = columns[i]\n",
    "        if f1=='mvar47':\n",
    "            continue\n",
    "        for j in range(i):\n",
    "            f2 = columns[j]\n",
    "            if f2=='mvar47':\n",
    "                continue\n",
    "            if str(f1) + '*' + str(f2) in cols_list or str(f2) + '*' + str(f1) in cols_list:\n",
    "                y[str(f1)+'*'+str(f2)] = X[f1]*X[f2]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mvar1</th>\n",
       "      <th>mvar2</th>\n",
       "      <th>mvar3</th>\n",
       "      <th>mvar4</th>\n",
       "      <th>mvar5</th>\n",
       "      <th>mvar6</th>\n",
       "      <th>mvar7</th>\n",
       "      <th>mvar8</th>\n",
       "      <th>mvar9</th>\n",
       "      <th>mvar10</th>\n",
       "      <th>...</th>\n",
       "      <th>mvar48*mvar34</th>\n",
       "      <th>mvar48*mvar35</th>\n",
       "      <th>mvar48*mvar36</th>\n",
       "      <th>mvar48*mvar37</th>\n",
       "      <th>mvar48*mvar38</th>\n",
       "      <th>mvar48*mvar39</th>\n",
       "      <th>mvar48*mvar42</th>\n",
       "      <th>mvar48*mvar43</th>\n",
       "      <th>mvar48*mvar44</th>\n",
       "      <th>mvar48*mvar46</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47000.000000</td>\n",
       "      <td>47000.000000</td>\n",
       "      <td>47000.000000</td>\n",
       "      <td>47000.000000</td>\n",
       "      <td>4.700000e+04</td>\n",
       "      <td>47000.000000</td>\n",
       "      <td>4.700000e+04</td>\n",
       "      <td>47000.000000</td>\n",
       "      <td>4.700000e+04</td>\n",
       "      <td>4.700000e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.700000e+04</td>\n",
       "      <td>47000.000000</td>\n",
       "      <td>47000.000000</td>\n",
       "      <td>47000.000000</td>\n",
       "      <td>47000.000000</td>\n",
       "      <td>47000.000000</td>\n",
       "      <td>4.700000e+04</td>\n",
       "      <td>47000.000000</td>\n",
       "      <td>47000.000000</td>\n",
       "      <td>47000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1742.722986</td>\n",
       "      <td>1.079593</td>\n",
       "      <td>5.337719</td>\n",
       "      <td>0.455771</td>\n",
       "      <td>1.115285e+00</td>\n",
       "      <td>1487.051601</td>\n",
       "      <td>1.674842e+04</td>\n",
       "      <td>5632.693128</td>\n",
       "      <td>3.037784e+04</td>\n",
       "      <td>3.108487e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>6.546261e-02</td>\n",
       "      <td>0.070940</td>\n",
       "      <td>1.787222</td>\n",
       "      <td>1.164540</td>\n",
       "      <td>1.212376</td>\n",
       "      <td>0.025735</td>\n",
       "      <td>9.849718e-02</td>\n",
       "      <td>1.852716</td>\n",
       "      <td>0.207485</td>\n",
       "      <td>0.020019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>96.007464</td>\n",
       "      <td>1.656391</td>\n",
       "      <td>11.004566</td>\n",
       "      <td>1.802979</td>\n",
       "      <td>6.064693e+00</td>\n",
       "      <td>3329.088778</td>\n",
       "      <td>4.801932e+04</td>\n",
       "      <td>9372.432312</td>\n",
       "      <td>5.220191e+04</td>\n",
       "      <td>6.830341e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.939260e-01</td>\n",
       "      <td>0.144556</td>\n",
       "      <td>1.525478</td>\n",
       "      <td>1.316958</td>\n",
       "      <td>1.153803</td>\n",
       "      <td>0.117467</td>\n",
       "      <td>1.118705e-01</td>\n",
       "      <td>1.825213</td>\n",
       "      <td>0.073689</td>\n",
       "      <td>0.084405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1494.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.551115e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.637979e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.775558e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.851118e-17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1673.000000</td>\n",
       "      <td>0.139472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.789685e+03</td>\n",
       "      <td>668.000000</td>\n",
       "      <td>2.336388e+03</td>\n",
       "      <td>1.093000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.606817e-18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.797717</td>\n",
       "      <td>0.265906</td>\n",
       "      <td>0.493703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.512183</td>\n",
       "      <td>0.151792</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1738.000000</td>\n",
       "      <td>0.529300</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>496.000000</td>\n",
       "      <td>5.992000e+03</td>\n",
       "      <td>1692.714286</td>\n",
       "      <td>9.991337e+03</td>\n",
       "      <td>9.496500e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.578595e-18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.387511</td>\n",
       "      <td>0.746046</td>\n",
       "      <td>0.930280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.781413e-02</td>\n",
       "      <td>1.365238</td>\n",
       "      <td>0.217192</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1808.732955</td>\n",
       "      <td>1.370900</td>\n",
       "      <td>6.448500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1240.228571</td>\n",
       "      <td>1.670725e+04</td>\n",
       "      <td>6640.000000</td>\n",
       "      <td>3.765800e+04</td>\n",
       "      <td>3.462850e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.902309e-18</td>\n",
       "      <td>0.082371</td>\n",
       "      <td>2.262912</td>\n",
       "      <td>1.697184</td>\n",
       "      <td>1.638286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.669728e-01</td>\n",
       "      <td>2.735501</td>\n",
       "      <td>0.264512</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1950.000000</td>\n",
       "      <td>44.630100</td>\n",
       "      <td>286.858000</td>\n",
       "      <td>114.696000</td>\n",
       "      <td>2.265270e+02</td>\n",
       "      <td>136595.000000</td>\n",
       "      <td>5.549600e+06</td>\n",
       "      <td>266683.000000</td>\n",
       "      <td>3.711880e+06</td>\n",
       "      <td>5.633320e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.856290e+00</td>\n",
       "      <td>2.545776</td>\n",
       "      <td>27.288209</td>\n",
       "      <td>20.812670</td>\n",
       "      <td>30.483888</td>\n",
       "      <td>4.153605</td>\n",
       "      <td>1.200000e+00</td>\n",
       "      <td>29.200356</td>\n",
       "      <td>0.705323</td>\n",
       "      <td>5.374417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 843 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              mvar1         mvar2         mvar3         mvar4         mvar5  \\\n",
       "count  47000.000000  47000.000000  47000.000000  47000.000000  4.700000e+04   \n",
       "mean    1742.722986      1.079593      5.337719      0.455771  1.115285e+00   \n",
       "std       96.007464      1.656391     11.004566      1.802979  6.064693e+00   \n",
       "min     1494.000000      0.000000      0.000000      0.000000 -5.551115e-16   \n",
       "25%     1673.000000      0.139472      0.000000      0.000000  0.000000e+00   \n",
       "50%     1738.000000      0.529300      0.310000      0.000000  0.000000e+00   \n",
       "75%     1808.732955      1.370900      6.448500      0.000000  0.000000e+00   \n",
       "max     1950.000000     44.630100    286.858000    114.696000  2.265270e+02   \n",
       "\n",
       "               mvar6         mvar7          mvar8         mvar9        mvar10  \\\n",
       "count   47000.000000  4.700000e+04   47000.000000  4.700000e+04  4.700000e+04   \n",
       "mean     1487.051601  1.674842e+04    5632.693128  3.037784e+04  3.108487e+04   \n",
       "std      3329.088778  4.801932e+04    9372.432312  5.220191e+04  6.830341e+04   \n",
       "min         0.000000  0.000000e+00       0.000000  0.000000e+00 -3.637979e-12   \n",
       "25%        86.000000  1.789685e+03     668.000000  2.336388e+03  1.093000e+03   \n",
       "50%       496.000000  5.992000e+03    1692.714286  9.991337e+03  9.496500e+03   \n",
       "75%      1240.228571  1.670725e+04    6640.000000  3.765800e+04  3.462850e+04   \n",
       "max    136595.000000  5.549600e+06  266683.000000  3.711880e+06  5.633320e+06   \n",
       "\n",
       "       ...  mvar48*mvar34  mvar48*mvar35  mvar48*mvar36  mvar48*mvar37  \\\n",
       "count  ...   4.700000e+04   47000.000000   47000.000000   47000.000000   \n",
       "mean   ...   6.546261e-02       0.070940       1.787222       1.164540   \n",
       "std    ...   1.939260e-01       0.144556       1.525478       1.316958   \n",
       "min    ...  -2.775558e-17       0.000000       0.000000       0.000000   \n",
       "25%    ...  -8.606817e-18       0.000000       0.797717       0.265906   \n",
       "50%    ...  -7.578595e-18       0.000000       1.387511       0.746046   \n",
       "75%    ...  -6.902309e-18       0.082371       2.262912       1.697184   \n",
       "max    ...   4.856290e+00       2.545776      27.288209      20.812670   \n",
       "\n",
       "       mvar48*mvar38  mvar48*mvar39  mvar48*mvar42  mvar48*mvar43  \\\n",
       "count   47000.000000   47000.000000   4.700000e+04   47000.000000   \n",
       "mean        1.212376       0.025735   9.849718e-02       1.852716   \n",
       "std         1.153803       0.117467   1.118705e-01       1.825213   \n",
       "min         0.000000       0.000000  -3.851118e-17       0.000000   \n",
       "25%         0.493703       0.000000   0.000000e+00       0.512183   \n",
       "50%         0.930280       0.000000   5.781413e-02       1.365238   \n",
       "75%         1.638286       0.000000   1.669728e-01       2.735501   \n",
       "max        30.483888       4.153605   1.200000e+00      29.200356   \n",
       "\n",
       "       mvar48*mvar44  mvar48*mvar46  \n",
       "count   47000.000000   47000.000000  \n",
       "mean        0.207485       0.020019  \n",
       "std         0.073689       0.084405  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.151792       0.000000  \n",
       "50%         0.217192       0.000000  \n",
       "75%         0.264512       0.000000  \n",
       "max         0.705323       5.374417  \n",
       "\n",
       "[8 rows x 843 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = pickle.load(open('cols_list.sav', 'rb'))\n",
    "X_inter = col_creator(col_list, X_rescaled)\n",
    "X_inter.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = pickle.load(open('post_KNN_scaler.sav', 'rb'))\n",
    "X_inter_scaled = pd.DataFrame(scaler.transform(X_inter), columns=X_inter.columns, index=X_inter.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = pickle.load(open('PCA.sav', 'rb'))\n",
    "X_test_pca = pd.DataFrame(pca.transform(X_inter_scaled), index=X_inter_scaled.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_data, models, thresh, weights=None):\n",
    "    \n",
    "    if weights == None:\n",
    "        weights = np.ones(len(models))\n",
    "    \n",
    "    N = len(models)\n",
    "    ypred_final = np.zeros(test_data.shape[0])\n",
    "    \n",
    "    for i in range(N):\n",
    "        if thresh[i]==None:\n",
    "            print('Using XGBoost')\n",
    "            ypred_final += weights[i]*models[i].predict(test_data)\n",
    "        \n",
    "        else:\n",
    "            print('Using LightBoost with Threshold =', thresh[i])\n",
    "            y_test_prob = models[i].predict(test_data)    \n",
    "            y_pred_test = np.zeros(len(y_test_prob))\n",
    "            y_pred_test[np.argwhere(y_test_prob>thresh[i])] = 1 \n",
    "            \n",
    "            ypred_final += weights[i]*y_pred_test\n",
    "            \n",
    "       \n",
    "    ypred_final = ypred_final/sum(weights)\n",
    "    \n",
    "    y_hat_test = np.zeros(test_data.shape[0])\n",
    "    y_hat_test[np.argwhere(ypred_final>0.5)] = 1\n",
    "    \n",
    "    y = pd.DataFrame(y_hat_test, index=test_data.index)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LightBoost with Threshold = 0.5\n",
      "Using LightBoost with Threshold = 0.5\n",
      "Using XGBoost\n",
      "Using LightBoost with Threshold = 0.5\n",
      "Using LightBoost with Threshold = 0.5\n",
      "Using LightBoost with Threshold = 0.5\n",
      "Using LightBoost with Threshold = 0.6\n",
      "Using LightBoost with Threshold = 0.6\n",
      "Using LightBoost with Threshold = 0.6\n",
      "Using LightBoost with Threshold = 0.6\n",
      "Using LightBoost with Threshold = 0.6\n",
      "Using LightBoost with Threshold = 0.45\n",
      "Using LightBoost with Threshold = 0.45\n",
      "Using XGBoost\n",
      "Using LightBoost with Threshold = 0.45\n",
      "Using LightBoost with Threshold = 0.45\n",
      "Using XGBoost\n",
      "Using LightBoost with Threshold = 0.5\n",
      "Using XGBoost\n",
      "Using LightBoost with Threshold = 0.5\n"
     ]
    }
   ],
   "source": [
    "models = pickle.load(open('models.sav', 'rb'))\n",
    "thresholds = pickle.load(open('thresholds.sav', 'rb'))\n",
    "y_hat_test = predict(X_test_pca, models, thresh = thresholds) ##Get t from grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test.to_csv('Predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
