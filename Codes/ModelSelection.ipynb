{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as gbm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>default_ind</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230032</th>\n",
       "      <td>7.696114</td>\n",
       "      <td>12.350336</td>\n",
       "      <td>-2.147227</td>\n",
       "      <td>2.495844</td>\n",
       "      <td>-4.748575</td>\n",
       "      <td>-2.381941</td>\n",
       "      <td>-4.644673</td>\n",
       "      <td>0.773259</td>\n",
       "      <td>-1.294904</td>\n",
       "      <td>1.278156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279910</td>\n",
       "      <td>-0.345718</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.172868</td>\n",
       "      <td>0.324652</td>\n",
       "      <td>0.390063</td>\n",
       "      <td>-0.425547</td>\n",
       "      <td>-0.468056</td>\n",
       "      <td>-0.097686</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230033</th>\n",
       "      <td>-5.545660</td>\n",
       "      <td>-2.045987</td>\n",
       "      <td>-4.134448</td>\n",
       "      <td>0.614403</td>\n",
       "      <td>1.725154</td>\n",
       "      <td>-0.641462</td>\n",
       "      <td>-1.716193</td>\n",
       "      <td>-0.838565</td>\n",
       "      <td>-1.208660</td>\n",
       "      <td>0.701930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303886</td>\n",
       "      <td>-0.067337</td>\n",
       "      <td>-0.304120</td>\n",
       "      <td>0.423952</td>\n",
       "      <td>-0.186540</td>\n",
       "      <td>-0.484241</td>\n",
       "      <td>-0.008021</td>\n",
       "      <td>0.345614</td>\n",
       "      <td>-0.319914</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230034</th>\n",
       "      <td>-5.525988</td>\n",
       "      <td>-2.312766</td>\n",
       "      <td>-1.993475</td>\n",
       "      <td>1.496010</td>\n",
       "      <td>-2.269309</td>\n",
       "      <td>1.707946</td>\n",
       "      <td>-1.655883</td>\n",
       "      <td>1.098356</td>\n",
       "      <td>0.146529</td>\n",
       "      <td>-0.700801</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290246</td>\n",
       "      <td>0.392103</td>\n",
       "      <td>0.135142</td>\n",
       "      <td>-1.019374</td>\n",
       "      <td>-0.270207</td>\n",
       "      <td>-0.572938</td>\n",
       "      <td>0.129733</td>\n",
       "      <td>0.276641</td>\n",
       "      <td>-0.015634</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230035</th>\n",
       "      <td>-5.967580</td>\n",
       "      <td>-2.611269</td>\n",
       "      <td>-1.989661</td>\n",
       "      <td>1.968232</td>\n",
       "      <td>-0.433192</td>\n",
       "      <td>0.345623</td>\n",
       "      <td>-1.086218</td>\n",
       "      <td>1.180024</td>\n",
       "      <td>-1.332320</td>\n",
       "      <td>-0.355089</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036557</td>\n",
       "      <td>-0.185665</td>\n",
       "      <td>0.158475</td>\n",
       "      <td>0.303761</td>\n",
       "      <td>-0.186965</td>\n",
       "      <td>-0.086659</td>\n",
       "      <td>-0.155855</td>\n",
       "      <td>0.148110</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230036</th>\n",
       "      <td>-6.760282</td>\n",
       "      <td>-3.222255</td>\n",
       "      <td>-2.508281</td>\n",
       "      <td>3.129283</td>\n",
       "      <td>0.563894</td>\n",
       "      <td>0.820464</td>\n",
       "      <td>-1.270672</td>\n",
       "      <td>1.217419</td>\n",
       "      <td>-0.440856</td>\n",
       "      <td>1.105332</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201644</td>\n",
       "      <td>0.327657</td>\n",
       "      <td>-0.169663</td>\n",
       "      <td>-0.053480</td>\n",
       "      <td>-0.469242</td>\n",
       "      <td>-0.257605</td>\n",
       "      <td>-0.497360</td>\n",
       "      <td>0.469798</td>\n",
       "      <td>-0.096623</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0          1         2         3         4         5  \\\n",
       "application_key                                                                \n",
       "230032           7.696114  12.350336 -2.147227  2.495844 -4.748575 -2.381941   \n",
       "230033          -5.545660  -2.045987 -4.134448  0.614403  1.725154 -0.641462   \n",
       "230034          -5.525988  -2.312766 -1.993475  1.496010 -2.269309  1.707946   \n",
       "230035          -5.967580  -2.611269 -1.989661  1.968232 -0.433192  0.345623   \n",
       "230036          -6.760282  -3.222255 -2.508281  3.129283  0.563894  0.820464   \n",
       "\n",
       "                        6         7         8         9  ...       191  \\\n",
       "application_key                                          ...             \n",
       "230032          -4.644673  0.773259 -1.294904  1.278156  ...  0.279910   \n",
       "230033          -1.716193 -0.838565 -1.208660  0.701930  ... -0.303886   \n",
       "230034          -1.655883  1.098356  0.146529 -0.700801  ... -0.290246   \n",
       "230035          -1.086218  1.180024 -1.332320 -0.355089  ... -0.036557   \n",
       "230036          -1.270672  1.217419 -0.440856  1.105332  ...  0.201644   \n",
       "\n",
       "                      192       193       194       195       196       197  \\\n",
       "application_key                                                               \n",
       "230032          -0.345718  0.113600  0.172868  0.324652  0.390063 -0.425547   \n",
       "230033          -0.067337 -0.304120  0.423952 -0.186540 -0.484241 -0.008021   \n",
       "230034           0.392103  0.135142 -1.019374 -0.270207 -0.572938  0.129733   \n",
       "230035          -0.185665  0.158475  0.303761 -0.186965 -0.086659 -0.155855   \n",
       "230036           0.327657 -0.169663 -0.053480 -0.469242 -0.257605 -0.497360   \n",
       "\n",
       "                      198       199  default_ind  \n",
       "application_key                                   \n",
       "230032          -0.468056 -0.097686          0.0  \n",
       "230033           0.345614 -0.319914          1.0  \n",
       "230034           0.276641 -0.015634          1.0  \n",
       "230035           0.148110  0.003742          0.0  \n",
       "230036           0.469798 -0.096623          0.0  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('TrainDataScaledPCA.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('default_ind', axis=1)  \n",
    "y = data['default_ind']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "train_data = pd.DataFrame.copy(X_train)\n",
    "train_data['default_ind']  = y_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " 0.0 % Done\n",
      "t = 0.45 Number of Estimators = 50 Depth = 1\n",
      "\n",
      "Train Score XGB = 0.684547765303961\n",
      "Train F1 Score XGB = 0.7166841053933226\n",
      "Train Precision XGB= 0.650422997237569\n",
      "Train Recall XGB= 0.7979771234907859\n",
      "\n",
      "Train Score LB = 0.6737714467273883\n",
      "Train F1 Score LB = 0.718705052396064\n",
      "Train Precision LB= 0.631697234819601\n",
      "Train Recall LB= 0.8335098496081339\n",
      "\n",
      "Test Score XGB = 0.6380472402695975\n",
      "Test F1 Score XGB = 0.5602360752489857\n",
      "Test Precision XGB= 0.4315263098079327\n",
      "Test Recall XGB= 0.7983599663582843\n",
      "\n",
      "Test Score LB= 0.6055619649037586\n",
      "Test F1 Score LB= 0.5493270431524906\n",
      "Test Precision LB= 0.40991923793746116\n",
      "Test Recall LB= 0.8324222035323802\n",
      "\n",
      "\n",
      " 0.694 % Done\n",
      "t = 0.45 Number of Estimators = 50 Depth = 2\n",
      "\n",
      "Train Score XGB = 0.7027907223045965\n",
      "Train F1 Score XGB = 0.7203189236327394\n",
      "Train Precision XGB= 0.6802032845513152\n",
      "Train Recall XGB= 0.765462825672527\n",
      "\n",
      "Train Score LB = 0.6929675916119467\n",
      "Train F1 Score LB = 0.7259665374799129\n",
      "Train Precision LB= 0.6555138272447935\n",
      "Train Recall LB= 0.8133869942808727\n",
      "\n",
      "Test Score XGB = 0.6760580484546724\n",
      "Test F1 Score XGB = 0.5775595850819543\n",
      "Test Precision XGB= 0.4632287565095897\n",
      "Test Recall XGB= 0.7668208578637511\n",
      "\n",
      "Test Score LB= 0.6422369299896776\n",
      "Test F1 Score LB= 0.5680985192786983\n",
      "Test Precision LB= 0.4360792257483682\n",
      "Test Recall LB= 0.8147603027754415\n",
      "\n",
      "\n",
      " 1.389 % Done\n",
      "t = 0.45 Number of Estimators = 50 Depth = 3\n",
      "\n",
      "Train Score XGB = 0.7152351196780343\n",
      "Train F1 Score XGB = 0.7233298176111954\n",
      "Train Precision XGB= 0.7033368352593926\n",
      "Train Recall XGB= 0.7444926922262233\n",
      "\n",
      "Train Score LB = 0.7052796017792841\n",
      "Train F1 Score LB = 0.7317508133510062\n",
      "Train Precision LB= 0.6714431029145106\n",
      "Train Recall LB= 0.803961025206524\n",
      "\n",
      "Test Score XGB = 0.6957313740967879\n",
      "Test F1 Score XGB = 0.5850790759294526\n",
      "Test Precision XGB= 0.4825843464007649\n",
      "Test Recall XGB= 0.7428511354079058\n",
      "\n",
      "Test Score LB= 0.6606351326735078\n",
      "Test F1 Score LB= 0.5763020241073459\n",
      "Test Precision LB= 0.45062240663900416\n",
      "Test Recall LB= 0.7992010092514719\n",
      "\n",
      "\n",
      " 2.083 % Done\n",
      "t = 0.45 Number of Estimators = 50 Depth = 5\n",
      "\n",
      "Train Score XGB = 0.747696462613853\n",
      "Train F1 Score XGB = 0.7496650466307632\n",
      "Train Precision XGB= 0.7438611125593034\n",
      "Train Recall XGB= 0.7555602626562169\n",
      "\n",
      "Train Score LB = 0.7349872908282143\n",
      "Train F1 Score LB = 0.7524669222208483\n",
      "Train Precision LB= 0.7059069184724607\n",
      "Train Recall LB= 0.8056026265621691\n",
      "\n",
      "Test Score XGB = 0.7092112453700893\n",
      "Test F1 Score XGB = 0.5904387240229196\n",
      "Test Precision XGB= 0.4976214501946086\n",
      "Test Recall XGB= 0.7258200168208578\n",
      "\n",
      "Test Score LB= 0.6820693424008744\n",
      "Test F1 Score LB= 0.5877165354330708\n",
      "Test Precision LB= 0.4697885196374622\n",
      "Test Recall LB= 0.7846930193439865\n",
      "\n",
      "\n",
      " 2.778 % Done\n",
      "t = 0.45 Number of Estimators = 50 Depth = 10\n",
      "\n",
      "Train Score XGB = 0.9772029231095107\n",
      "Train F1 Score XGB = 0.9772841199905021\n",
      "Train Precision XGB= 0.9738156580261843\n",
      "Train Recall XGB= 0.9807773776742216\n",
      "\n",
      "Train Score LB = 0.7459224740521077\n",
      "Train F1 Score LB = 0.76011199440028\n",
      "Train Precision LB= 0.7199071881806989\n",
      "Train Recall LB= 0.8050730777377674\n",
      "\n",
      "Test Score XGB = 0.70927196551096\n",
      "Test F1 Score XGB = 0.584230635637374\n",
      "Test Precision XGB= 0.4976331360946746\n",
      "Test Recall XGB= 0.7073170731707317\n",
      "\n",
      "Test Score LB= 0.6876555953609812\n",
      "Test F1 Score LB= 0.5892686042797828\n",
      "Test Precision LB= 0.4750257466529351\n",
      "Test Recall LB= 0.7758620689655172\n",
      "\n",
      "\n",
      " 3.472 % Done\n",
      "t = 0.45 Number of Estimators = 50 Depth = 15\n"
     ]
    }
   ],
   "source": [
    "models_XGB = []\n",
    "models_LB = []\n",
    "\n",
    "ns = [50, 100, 200, 300, 400, 500]\n",
    "max_depths = [1, 2, 3, 5, 10, 15]\n",
    "ts = [0.45, 0.5, 0.55, 0.6]\n",
    "\n",
    "i = 0\n",
    "\n",
    "pos_class = train_data[train_data['default_ind']==1]\n",
    "neg_class = train_data[train_data['default_ind']==0]\n",
    "neg_resampled = neg_class.sample(n= int(1 * len(pos_class)), replace=False)\n",
    "\n",
    "train_data_resampled = pd.concat([pos_class, neg_resampled])\n",
    "\n",
    "# Use these for Trainings\n",
    "\n",
    "X_train_resampled = train_data_resampled.drop('default_ind', axis=1)\n",
    "y_train_resampled = train_data_resampled['default_ind']    \n",
    "\n",
    "\n",
    "for t in ts: \n",
    "    for n in ns:\n",
    "        for max_depth in max_depths:\n",
    "\n",
    "            print('\\n\\n', round(i/144*100, 3), '% Done')\n",
    "            i += 1\n",
    "            print('t =', t, 'Number of Estimators =', n, 'Depth =', max_depth)\n",
    "\n",
    "            #Training\n",
    "\n",
    "            #XGBoost\n",
    "            model_XGB = XGBClassifier(n_estimators = n , learning_rate=0.1, max_depth=max_depth ,reg_lambda=0.01, n_jobs = -1, verbose =100) \n",
    "            model_XGB.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "            y_hat_XGB = model_XGB.predict(X_train_resampled)\n",
    "            print('\\nTrain Score XGB =', accuracy_score(y_train_resampled, y_hat_XGB))\n",
    "            print('Train F1 Score XGB =', f1_score(y_train_resampled, y_hat_XGB))    \n",
    "            print('Train Precision XGB=', precision_score(y_train_resampled, y_hat_XGB))\n",
    "            print('Train Recall XGB=', recall_score(y_train_resampled, y_hat_XGB))\n",
    "\n",
    "\n",
    "        #     #AdaBoost\n",
    "        #     model_AB = AdaBoostClassifier(n_estimators = ns[model_no], learning_rate=0.1, base_estimator=DecisionTreeClassifier(max_depth=5)) \n",
    "        #     model_AB.fit(X_train_resampled, y_train_resampled)  \n",
    "\n",
    "        #     y_hat_AB = model_AB.predict(X_train_resampled)\n",
    "        #     print('Train Score AB =', accuracy_score(y_train_resampled, y_hat_AB))\n",
    "        #     print('Train F1 Score AB=', f1_score(y_train_resampled, y_hat_AB))\n",
    "        #     print('Train Precision AB=' precision_score(y_train_resampled, y_hat_AB))\n",
    "        #     print('Train Recall AB=' recall_score(y_train_resampled, y_hat_AB))\n",
    "\n",
    "            #LightBoost\n",
    "            cv_params = {\n",
    "            'max_depth': max_depth,\n",
    "            'objective': 'binary',\n",
    "            'metric':'auc',  \n",
    "            'feature_fraction': 1, \n",
    "            'bagging_fraction': 0.75,\n",
    "            'reg_lambda': 1,\n",
    "            'n_estimators': n\n",
    "            }\n",
    "\n",
    "            gbm_train = gbm.Dataset(X_train_resampled, y_train_resampled)\n",
    "            model_LB = gbm.train(cv_params,  \n",
    "                        gbm_train, \n",
    "                        num_boost_round=900,\n",
    "                        verbose_eval=1)\n",
    "\n",
    "            y_train_prob = model_LB.predict(X_train_resampled)\n",
    "            thres = t\n",
    "            y_pred_train = np.zeros(len(y_train_prob))\n",
    "            y_pred_train[np.argwhere(y_train_prob>thres)] = 1\n",
    "            print('\\nTrain Score LB =', accuracy_score(y_train_resampled, y_pred_train))\n",
    "            print('Train F1 Score LB =', f1_score(y_train_resampled, y_pred_train))\n",
    "            print('Train Precision LB=', precision_score(y_train_resampled, y_pred_train))\n",
    "            print('Train Recall LB=', recall_score(y_train_resampled, y_pred_train))\n",
    "\n",
    "            #Test Scores, accuracy\n",
    "\n",
    "            y_test_predXGB = model_XGB.predict(X_test)\n",
    "            print('\\nTest Score XGB =', accuracy_score(y_test, y_test_predXGB))\n",
    "            print('Test F1 Score XGB =', f1_score(y_test, y_test_predXGB)) \n",
    "            print('Test Precision XGB=', precision_score(y_test, y_test_predXGB))\n",
    "            print('Test Recall XGB=', recall_score(y_test, y_test_predXGB))\n",
    "\n",
    "\n",
    "        #     y_test_predAB = model_AB.predict(X_test)\n",
    "        #     print('Test Score AB =', accuracy_score(y_test, y_test_predAB))\n",
    "        #     print('Test F1 Score AB =', f1_score(y_test, y_test_predAB))\n",
    "\n",
    "            y_test_prob = model_LB.predict(X_test)    \n",
    "            y_pred_test = np.zeros(len(y_test_prob))\n",
    "            y_pred_test[np.argwhere(y_test_prob>thres)] = 1    \n",
    "            print('\\nTest Score LB=', accuracy_score(y_test, y_pred_test))\n",
    "            print('Test F1 Score LB=', f1_score(y_test, y_pred_test))\n",
    "            print('Test Precision LB=', precision_score(y_test, y_pred_test))\n",
    "            print('Test Recall LB=', recall_score(y_test, y_pred_test))\n",
    "\n",
    "\n",
    "            models_XGB.append(model_XGB)\n",
    "            models_LB.append(model_LB)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
